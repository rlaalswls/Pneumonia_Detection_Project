{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPFLSUyGDZEF0/JlwbOnKEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlaalswls/Pneumonia_Detection_Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "print('üîß ÌôòÍ≤Ω ÏÑ§Ï†ï')\n",
        "print('=' * 50)\n",
        "print(f'PyTorch Î≤ÑÏ†Ñ: {torch.__version__}')\n",
        "print(f'CUDA ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU Ïù¥Î¶Ñ: {torch.cuda.get_device_name(0)}')\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'GPU Î©îÎ™®Î¶¨: {gpu_mem:.2f} GB')\n",
        "else:\n",
        "    print('‚ö†Ô∏è GPU ÏÇ¨Ïö© Î∂àÍ∞Ä. Îü∞ÌÉÄÏûÑ > Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤ΩÏóêÏÑú GPU ÏÑ†ÌÉù ÌïÑÏöî')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4btG9nkghJJt",
        "outputId": "22bc5eb9-3b00-4d95-dcea-19c9d71fc911"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
            "==================================================\n",
            "PyTorch Î≤ÑÏ†Ñ: 2.9.0+cu126\n",
            "CUDA ÏÇ¨Ïö© Í∞ÄÎä•: True\n",
            "GPU Ïù¥Î¶Ñ: NVIDIA A100-SXM4-40GB\n",
            "GPU Î©îÎ™®Î¶¨: 42.47 GB\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF7paPpHhPmW",
        "outputId": "8c8aa7ee-6571-474f-f8c9-81ec40411bf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17779, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 17779 (delta 0), reused 0 (delta 0), pack-reused 17772 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17779/17779), 16.92 MiB | 30.08 MiB/s, done.\n",
            "Resolving deltas: 100% (12128/12128), done.\n",
            "/content/yolov5\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HkZsE4hRpN",
        "outputId": "bf49f4a4-cd2a-4357-aef9-eebdd1ae480a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = {\n",
        "    \"root\": os.path.join(drive_path, 'roboflow', 'pneumonia-detector'),\n",
        "}\n",
        "\n",
        "DATASET[\"yaml\"] = os.path.join(DATASET[\"root\"], \"data.yaml\")\n",
        "DATASET[\"runs\"] = os.path.join(DATASET[\"root\"], \"runs\")"
      ],
      "metadata": {
        "id": "7UkR4PgYhXaH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #CLAHE Ï†ÅÏö© ÏãúÏûë\n",
        "# DATASET[\"clahe_processed\"] = os.path.join(DATASET[\"root\"], \"clahe_processed\")"
      ],
      "metadata": {
        "id": "UMmUn93-oA6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 12. CLAHE Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
        "# import cv2\n",
        "# import shutil\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def apply_clahe_to_dataset(source_root, dest_root):\n",
        "#     print(\"üîÑ CLAHE Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë...\")\n",
        "\n",
        "#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "#     splits = ['train', 'valid', 'test']\n",
        "\n",
        "#     for split in splits:\n",
        "#         src_img_dir = os.path.join(source_root, split, 'images')\n",
        "#         dst_img_dir = os.path.join(dest_root, split, 'images')\n",
        "#         src_label_dir = os.path.join(source_root, split, 'labels')\n",
        "#         dst_label_dir = os.path.join(dest_root, split, 'labels')\n",
        "\n",
        "#         os.makedirs(dst_img_dir, exist_ok=True)\n",
        "#         os.makedirs(dst_label_dir, exist_ok=True)\n",
        "\n",
        "#         image_files = list(Path(src_img_dir).glob('*.jpg')) + \\\n",
        "#                      list(Path(src_img_dir).glob('*.png')) + \\\n",
        "#                      list(Path(src_img_dir).glob('*.jpeg'))\n",
        "\n",
        "#         print(f\"\\nÏ≤òÎ¶¨ Ï§ë: {split} ({len(image_files)}Í∞ú Ïù¥ÎØ∏ÏßÄ)\")\n",
        "\n",
        "#         for img_path in tqdm(image_files):\n",
        "#             img = cv2.imread(str(img_path))\n",
        "#             if img is None:\n",
        "#                 continue\n",
        "\n",
        "#             if len(img.shape) == 3:\n",
        "#                 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#             else:\n",
        "#                 gray = img\n",
        "\n",
        "#             clahe_img = clahe.apply(gray)\n",
        "#             clahe_bgr = cv2.cvtColor(clahe_img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "#             dst_path = os.path.join(dst_img_dir, img_path.name)\n",
        "#             cv2.imwrite(dst_path, clahe_bgr)\n",
        "\n",
        "#             label_name = img_path.stem + '.txt'\n",
        "#             src_label = os.path.join(src_label_dir, label_name)\n",
        "#             dst_label = os.path.join(dst_label_dir, label_name)\n",
        "\n",
        "#             if os.path.exists(src_label):\n",
        "#                 shutil.copy2(src_label, dst_label)\n",
        "\n",
        "#     print(\"\\n‚úÖ CLAHE Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å!\")\n",
        "\n",
        "# # Step 13. CLAHE Ï†ÅÏö©\n",
        "# apply_clahe_to_dataset(DATASET[\"root\"], DATASET[\"clahe_processed\"])\n",
        "\n",
        "# # Step 14. CLAHE data.yaml ÏÉùÏÑ±\n",
        "# if not os.path.exists(DATASET[\"clahe_processed\"]):\n",
        "#     os.makedirs(DATASET[\"clahe_processed\"], exist_ok=True)\n",
        "\n",
        "# data_yaml_clahe = {\n",
        "#     \"path\": DATASET[\"clahe_processed\"],\n",
        "#     \"train\": \"train/images\",\n",
        "#     \"val\": \"valid/images\",\n",
        "#     \"test\": \"test/images\",\n",
        "#     \"nc\": 1,\n",
        "#     \"names\": [\"Pneumonia\"]\n",
        "# }\n",
        "\n",
        "# clahe_yaml_path = os.path.join(DATASET[\"clahe_processed\"], \"data.yaml\")\n",
        "# with open(clahe_yaml_path, \"w\") as f:\n",
        "#     yaml.dump(data_yaml_clahe, f)\n",
        "\n",
        "# print(f\"‚úÖ CLAHE data.yaml ÏÉùÏÑ±: {clahe_yaml_path}\")\n"
      ],
      "metadata": {
        "id": "ij0-vyCYoBtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# # ÏòàÏãú: train Ïù¥ÎØ∏ÏßÄ 5Í∞ú ÌôïÏù∏\n",
        "# sample_images = list(Path(DATASET[\"clahe_processed\"], \"train/images\").glob(\"*.jpg\"))[:5]\n",
        "\n",
        "# for img_path in sample_images:\n",
        "#     img = cv2.imread(str(img_path))\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#     plt.imshow(img)\n",
        "#     plt.title(img_path.name)\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "mhCJUzMWoo0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 15. CLAHE ÌïôÏäµ\n",
        "# !python train.py \\\n",
        "#     --img {IMG_SIZE} \\\n",
        "#     --batch {BATCH_SIZE} \\\n",
        "#     --epochs {EPOCHS} \\\n",
        "#     --data {clahe_yaml_path} \\\n",
        "#     --weights yolov5s.pt \\\n",
        "#     --project {PROJECT_DIR} \\\n",
        "#     --name pneumonia_clahe \\\n",
        "#     --cache \\\n",
        "#     --patience 20"
      ],
      "metadata": {
        "id": "Snyyac7Covl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# from pathlib import Path\n",
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "# # CLAHE Î™®Îç∏ Í≤∞Í≥º Í≤ΩÎ°ú\n",
        "# results_path_clahe = os.path.join(PROJECT_DIR, \"pneumonia_clahe\")\n",
        "# results_csv_clahe = os.path.join(results_path_clahe, \"results.csv\")\n",
        "\n",
        "# if os.path.exists(results_csv_clahe):\n",
        "#     df = pd.read_csv(results_csv_clahe)\n",
        "#     df.columns = df.columns.str.strip()\n",
        "#     last_epoch = df.iloc[-1]\n",
        "\n",
        "#     precision_cols = [col for col in df.columns if 'precision' in col.lower()]\n",
        "#     recall_cols = [col for col in df.columns if 'recall' in col.lower()]\n",
        "\n",
        "#     if precision_cols and recall_cols:\n",
        "#         precision = last_epoch[precision_cols[0]]\n",
        "#         recall = last_epoch[recall_cols[0]]\n",
        "\n",
        "#         valid_labels_dir = os.path.join(DATASET[\"clahe_processed\"], \"valid\", \"labels\")\n",
        "#         valid_labels = list(Path(valid_labels_dir).glob(\"*.txt\"))\n",
        "\n",
        "#         total_gt_boxes = sum(len(open(f).readlines()) for f in valid_labels)\n",
        "\n",
        "#         TP = int(recall * total_gt_boxes)\n",
        "#         FN = total_gt_boxes - TP\n",
        "#         FP = int((TP / precision) - TP) if precision > 0 else 0\n",
        "#         TN = 0  # object detectionÏóêÏÑúÎäî Î≥¥ÌÜµ TN Í≥ÑÏÇ∞ Ïïà Ìï®\n",
        "\n",
        "#         # Confusion Matrix (Ïù¥ÎØ∏ÏßÄÎ°úÎßå)\n",
        "#         cm = np.array([[TP, FN],\n",
        "#                        [FP, TN]])\n",
        "\n",
        "#         plt.figure(figsize=(6,5))\n",
        "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "#                     xticklabels=['Pneumonia', 'Background'],\n",
        "#                     yticklabels=['Pneumonia', 'Background'],\n",
        "#                     cbar_kws={'label': 'Count'})\n",
        "#         plt.ylabel('Predicted')\n",
        "#         plt.xlabel('Actual')\n",
        "#         plt.title('Confusion Matrix - CLAHE (Counts)')\n",
        "\n",
        "#         # Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•\n",
        "#         cm_save_path = os.path.join(results_path_clahe, \"confusion_matrix_counts.png\")\n",
        "#         plt.savefig(cm_save_path, dpi=150, bbox_inches='tight')\n",
        "#         plt.show()\n"
      ],
      "metadata": {
        "id": "e2lHH3mRo1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# baseline code Ïã§Ìñâ Î∂ÄÎ∂Ñ #"
      ],
      "metadata": {
        "id": "lsT16oYxpNYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    \"path\": DATASET[\"root\"],\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\": \"valid/images\",\n",
        "    \"test\": \"test/images\",\n",
        "    \"nc\": 1,\n",
        "    \"names\": [\"Pneumonia\"]\n",
        "}\n",
        "\n",
        "with open(DATASET[\"yaml\"], \"w\") as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "print(f\"‚úÖ data.yaml ÏÉùÏÑ± ÏôÑÎ£å: {DATASET['yaml']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hJjRFcvhYTz",
        "outputId": "c1ee0e02-71c0-4a19-eed8-f5e801a88970"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml ÏÉùÏÑ± ÏôÑÎ£å: /content/drive/MyDrive/roboflow/pneumonia-detector/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment Config\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "PROJECT_DIR = DATASET[\"runs\"]"
      ],
      "metadata": {
        "id": "DrXQ8QHNhaW-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5 ÌïôÏäµ (Baseline - Ï¶ùÍ∞ï ÏóÜÏùå)\n",
        "!python train.py \\\n",
        "    --img {IMG_SIZE} \\\n",
        "    --batch {BATCH_SIZE} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --data {DATASET[\"yaml\"]} \\\n",
        "    --weights yolov5s.pt \\\n",
        "    --project {PROJECT_DIR} \\\n",
        "    --name pneumonia_baseline \\\n",
        "    --cache \\\n",
        "    --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN6QZ5d6hgKx",
        "outputId": "864fb44c-e821-420f-b324-0845b338e74d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.0GB ram):  67% 7897/11796 [1:27:16<43:05,  1.51it/s]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2# ÌïôÏäµÎêú Î™®Îç∏ Ï∞æÍ∏∞\n",
        "import glob as gb\n",
        "\n",
        "weight_files = gb.glob(f\"{PROJECT_DIR}/**/best.pt\", recursive=True)\n",
        "if weight_files:\n",
        "    BEST_WEIGHTS = weight_files[0]\n",
        "    print(f\"‚úÖ Î™®Îç∏ Î∞úÍ≤¨: {BEST_WEIGHTS}\")\n",
        "else:\n",
        "    BEST_WEIGHTS = os.path.join(PROJECT_DIR, \"pneumonia_baseline\", \"weights\", \"best.pt\")\n",
        "    print(f\"‚ö†Ô∏è Í∏∞Î≥∏ Í≤ΩÎ°ú ÏÇ¨Ïö©: {BEST_WEIGHTS}\")"
      ],
      "metadata": {
        "id": "3DsrfoqriTPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "results_path = os.path.join(PROJECT_DIR, \"pneumonia_baseline\")\n",
        "results_csv = os.path.join(results_path, \"results.csv\")\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    df = pd.read_csv(results_csv)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    last_epoch = df.iloc[-1]\n",
        "\n",
        "    precision_cols = [col for col in df.columns if 'precision' in col.lower()]\n",
        "    recall_cols = [col for col in df.columns if 'recall' in col.lower()]\n",
        "\n",
        "    if precision_cols and recall_cols:\n",
        "        precision = last_epoch[precision_cols[0]]\n",
        "        recall = last_epoch[recall_cols[0]]\n",
        "\n",
        "        # Validation GT Î∞ïÏä§ Ïàò\n",
        "        valid_labels_dir = os.path.join(DATASET[\"root\"], \"valid\", \"labels\")\n",
        "        valid_labels = list(Path(valid_labels_dir).glob(\"*.txt\"))\n",
        "        total_gt_boxes = sum(len(open(f).readlines()) for f in valid_labels)\n",
        "\n",
        "        # TP, FP, FN Í≥ÑÏÇ∞\n",
        "        TP = int(recall * total_gt_boxes)\n",
        "        FN = total_gt_boxes - TP\n",
        "        FP = int((TP / precision) - TP) if precision > 0 else 0\n",
        "        TN = 0\n",
        "\n",
        "        # Confusion Matrix ÏãúÍ∞ÅÌôî\n",
        "        cm = np.array([[TP, FN],\n",
        "                       [FP, TN]])\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Pneumonia', 'Background'],\n",
        "                    yticklabels=['Pneumonia', 'Background'],\n",
        "                    cbar_kws={'label':'Count'})\n",
        "        plt.ylabel('Predicted')\n",
        "        plt.xlabel('Actual')\n",
        "        plt.title('Confusion Matrix (Counts)')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "HGFnihbwiUyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}