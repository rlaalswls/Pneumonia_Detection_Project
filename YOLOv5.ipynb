{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPFLSUyGDZEF0/JlwbOnKEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlaalswls/Pneumonia_Detection_Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "print('üîß ÌôòÍ≤Ω ÏÑ§Ï†ï')\n",
        "print('=' * 50)\n",
        "print(f'PyTorch Î≤ÑÏ†Ñ: {torch.__version__}')\n",
        "print(f'CUDA ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU Ïù¥Î¶Ñ: {torch.cuda.get_device_name(0)}')\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'GPU Î©îÎ™®Î¶¨: {gpu_mem:.2f} GB')\n",
        "else:\n",
        "    print('‚ö†Ô∏è GPU ÏÇ¨Ïö© Î∂àÍ∞Ä. Îü∞ÌÉÄÏûÑ > Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤ΩÏóêÏÑú GPU ÏÑ†ÌÉù ÌïÑÏöî')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4btG9nkghJJt",
        "outputId": "22bc5eb9-3b00-4d95-dcea-19c9d71fc911"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
            "==================================================\n",
            "PyTorch Î≤ÑÏ†Ñ: 2.9.0+cu126\n",
            "CUDA ÏÇ¨Ïö© Í∞ÄÎä•: True\n",
            "GPU Ïù¥Î¶Ñ: NVIDIA A100-SXM4-40GB\n",
            "GPU Î©îÎ™®Î¶¨: 42.47 GB\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF7paPpHhPmW",
        "outputId": "8c8aa7ee-6571-474f-f8c9-81ec40411bf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17779, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 17779 (delta 0), reused 0 (delta 0), pack-reused 17772 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17779/17779), 16.92 MiB | 30.08 MiB/s, done.\n",
            "Resolving deltas: 100% (12128/12128), done.\n",
            "/content/yolov5\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HkZsE4hRpN",
        "outputId": "bf49f4a4-cd2a-4357-aef9-eebdd1ae480a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = {\n",
        "    \"root\": os.path.join(drive_path, 'roboflow', 'pneumonia-detector'),\n",
        "}\n",
        "\n",
        "DATASET[\"yaml\"] = os.path.join(DATASET[\"root\"], \"data.yaml\")\n",
        "DATASET[\"runs\"] = os.path.join(DATASET[\"root\"], \"runs\")"
      ],
      "metadata": {
        "id": "7UkR4PgYhXaH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #CLAHE Ï†ÅÏö© ÏãúÏûë\n",
        "# DATASET[\"clahe_processed\"] = os.path.join(DATASET[\"root\"], \"clahe_processed\")"
      ],
      "metadata": {
        "id": "UMmUn93-oA6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 12. CLAHE Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
        "# import cv2\n",
        "# import shutil\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def apply_clahe_to_dataset(source_root, dest_root):\n",
        "#     print(\"üîÑ CLAHE Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë...\")\n",
        "\n",
        "#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "#     splits = ['train', 'valid', 'test']\n",
        "\n",
        "#     for split in splits:\n",
        "#         src_img_dir = os.path.join(source_root, split, 'images')\n",
        "#         dst_img_dir = os.path.join(dest_root, split, 'images')\n",
        "#         src_label_dir = os.path.join(source_root, split, 'labels')\n",
        "#         dst_label_dir = os.path.join(dest_root, split, 'labels')\n",
        "\n",
        "#         os.makedirs(dst_img_dir, exist_ok=True)\n",
        "#         os.makedirs(dst_label_dir, exist_ok=True)\n",
        "\n",
        "#         image_files = list(Path(src_img_dir).glob('*.jpg')) + \\\n",
        "#                      list(Path(src_img_dir).glob('*.png')) + \\\n",
        "#                      list(Path(src_img_dir).glob('*.jpeg'))\n",
        "\n",
        "#         print(f\"\\nÏ≤òÎ¶¨ Ï§ë: {split} ({len(image_files)}Í∞ú Ïù¥ÎØ∏ÏßÄ)\")\n",
        "\n",
        "#         for img_path in tqdm(image_files):\n",
        "#             img = cv2.imread(str(img_path))\n",
        "#             if img is None:\n",
        "#                 continue\n",
        "\n",
        "#             if len(img.shape) == 3:\n",
        "#                 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#             else:\n",
        "#                 gray = img\n",
        "\n",
        "#             clahe_img = clahe.apply(gray)\n",
        "#             clahe_bgr = cv2.cvtColor(clahe_img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "#             dst_path = os.path.join(dst_img_dir, img_path.name)\n",
        "#             cv2.imwrite(dst_path, clahe_bgr)\n",
        "\n",
        "#             label_name = img_path.stem + '.txt'\n",
        "#             src_label = os.path.join(src_label_dir, label_name)\n",
        "#             dst_label = os.path.join(dst_label_dir, label_name)\n",
        "\n",
        "#             if os.path.exists(src_label):\n",
        "#                 shutil.copy2(src_label, dst_label)\n",
        "\n",
        "#     print(\"\\n‚úÖ CLAHE Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å!\")\n",
        "\n",
        "# # Step 13. CLAHE Ï†ÅÏö©\n",
        "# apply_clahe_to_dataset(DATASET[\"root\"], DATASET[\"clahe_processed\"])\n",
        "\n",
        "# # Step 14. CLAHE data.yaml ÏÉùÏÑ±\n",
        "# if not os.path.exists(DATASET[\"clahe_processed\"]):\n",
        "#     os.makedirs(DATASET[\"clahe_processed\"], exist_ok=True)\n",
        "\n",
        "# data_yaml_clahe = {\n",
        "#     \"path\": DATASET[\"clahe_processed\"],\n",
        "#     \"train\": \"train/images\",\n",
        "#     \"val\": \"valid/images\",\n",
        "#     \"test\": \"test/images\",\n",
        "#     \"nc\": 1,\n",
        "#     \"names\": [\"Pneumonia\"]\n",
        "# }\n",
        "\n",
        "# clahe_yaml_path = os.path.join(DATASET[\"clahe_processed\"], \"data.yaml\")\n",
        "# with open(clahe_yaml_path, \"w\") as f:\n",
        "#     yaml.dump(data_yaml_clahe, f)\n",
        "\n",
        "# print(f\"‚úÖ CLAHE data.yaml ÏÉùÏÑ±: {clahe_yaml_path}\")\n"
      ],
      "metadata": {
        "id": "ij0-vyCYoBtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# # ÏòàÏãú: train Ïù¥ÎØ∏ÏßÄ 5Í∞ú ÌôïÏù∏\n",
        "# sample_images = list(Path(DATASET[\"clahe_processed\"], \"train/images\").glob(\"*.jpg\"))[:5]\n",
        "\n",
        "# for img_path in sample_images:\n",
        "#     img = cv2.imread(str(img_path))\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#     plt.imshow(img)\n",
        "#     plt.title(img_path.name)\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "mhCJUzMWoo0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 15. CLAHE ÌïôÏäµ\n",
        "# !python train.py \\\n",
        "#     --img {IMG_SIZE} \\\n",
        "#     --batch {BATCH_SIZE} \\\n",
        "#     --epochs {EPOCHS} \\\n",
        "#     --data {clahe_yaml_path} \\\n",
        "#     --weights yolov5s.pt \\\n",
        "#     --project {PROJECT_DIR} \\\n",
        "#     --name pneumonia_clahe \\\n",
        "#     --cache \\\n",
        "#     --patience 20"
      ],
      "metadata": {
        "id": "Snyyac7Covl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# from pathlib import Path\n",
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "# # CLAHE Î™®Îç∏ Í≤∞Í≥º Í≤ΩÎ°ú\n",
        "# results_path_clahe = os.path.join(PROJECT_DIR, \"pneumonia_clahe\")\n",
        "# results_csv_clahe = os.path.join(results_path_clahe, \"results.csv\")\n",
        "\n",
        "# if os.path.exists(results_csv_clahe):\n",
        "#     df = pd.read_csv(results_csv_clahe)\n",
        "#     df.columns = df.columns.str.strip()\n",
        "#     last_epoch = df.iloc[-1]\n",
        "\n",
        "#     precision_cols = [col for col in df.columns if 'precision' in col.lower()]\n",
        "#     recall_cols = [col for col in df.columns if 'recall' in col.lower()]\n",
        "\n",
        "#     if precision_cols and recall_cols:\n",
        "#         precision = last_epoch[precision_cols[0]]\n",
        "#         recall = last_epoch[recall_cols[0]]\n",
        "\n",
        "#         valid_labels_dir = os.path.join(DATASET[\"clahe_processed\"], \"valid\", \"labels\")\n",
        "#         valid_labels = list(Path(valid_labels_dir).glob(\"*.txt\"))\n",
        "\n",
        "#         total_gt_boxes = sum(len(open(f).readlines()) for f in valid_labels)\n",
        "\n",
        "#         TP = int(recall * total_gt_boxes)\n",
        "#         FN = total_gt_boxes - TP\n",
        "#         FP = int((TP / precision) - TP) if precision > 0 else 0\n",
        "#         TN = 0  # object detectionÏóêÏÑúÎäî Î≥¥ÌÜµ TN Í≥ÑÏÇ∞ Ïïà Ìï®\n",
        "\n",
        "#         # Confusion Matrix (Ïù¥ÎØ∏ÏßÄÎ°úÎßå)\n",
        "#         cm = np.array([[TP, FN],\n",
        "#                        [FP, TN]])\n",
        "\n",
        "#         plt.figure(figsize=(6,5))\n",
        "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "#                     xticklabels=['Pneumonia', 'Background'],\n",
        "#                     yticklabels=['Pneumonia', 'Background'],\n",
        "#                     cbar_kws={'label': 'Count'})\n",
        "#         plt.ylabel('Predicted')\n",
        "#         plt.xlabel('Actual')\n",
        "#         plt.title('Confusion Matrix - CLAHE (Counts)')\n",
        "\n",
        "#         # Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•\n",
        "#         cm_save_path = os.path.join(results_path_clahe, \"confusion_matrix_counts.png\")\n",
        "#         plt.savefig(cm_save_path, dpi=150, bbox_inches='tight')\n",
        "#         plt.show()\n"
      ],
      "metadata": {
        "id": "e2lHH3mRo1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# baseline code Ïã§Ìñâ Î∂ÄÎ∂Ñ #"
      ],
      "metadata": {
        "id": "lsT16oYxpNYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    \"path\": DATASET[\"root\"],\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\": \"valid/images\",\n",
        "    \"test\": \"test/images\",\n",
        "    \"nc\": 1,\n",
        "    \"names\": [\"Pneumonia\"]\n",
        "}\n",
        "\n",
        "with open(DATASET[\"yaml\"], \"w\") as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "print(f\"‚úÖ data.yaml ÏÉùÏÑ± ÏôÑÎ£å: {DATASET['yaml']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hJjRFcvhYTz",
        "outputId": "c1ee0e02-71c0-4a19-eed8-f5e801a88970"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml ÏÉùÏÑ± ÏôÑÎ£å: /content/drive/MyDrive/roboflow/pneumonia-detector/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment Config\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "PROJECT_DIR = DATASET[\"runs\"]"
      ],
      "metadata": {
        "id": "DrXQ8QHNhaW-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5 ÌïôÏäµ (Baseline - Ï¶ùÍ∞ï ÏóÜÏùå)\n",
        "!python train.py \\\n",
        "    --img {IMG_SIZE} \\\n",
        "    --batch {BATCH_SIZE} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --data {DATASET[\"yaml\"]} \\\n",
        "    --weights yolov5s.pt \\\n",
        "    --project {PROJECT_DIR} \\\n",
        "    --name pneumonia_baseline \\\n",
        "    --cache \\\n",
        "    --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN6QZ5d6hgKx",
        "outputId": "9077115c-3780-4805-b206-ff7a6125eebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2026-01-15 07:37:51.105094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768462671.126408    6261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768462671.132909    6261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768462671.149623    6261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768462671.149653    6261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768462671.149656    6261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768462671.149659    6261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m02junseo-lee\u001b[0m (\u001b[33m02junseo-lee-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/roboflow/pneumonia-detector/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/roboflow/pneumonia-detector/runs, name=pneumonia_baseline, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=20, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-456-ge8245f0a Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/roboflow/pneumonia-detector/runs', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov5/wandb/run-20260115_073822-yikgu7wc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpneumonia_baseline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/02junseo-lee-student/runs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/02junseo-lee-student/runs/runs/yikgu7wc\u001b[0m\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.1MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 123MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "/content/yolov5/models/common.py:899: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/content/yolov5/models/common.py:899: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/roboflow/pneumonia-detector/train/labels.cache... 11796 images, 0 backgrounds, 0 corrupt: 100% 11796/11796 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.0GB ram):  66% 7823/11796 [1:26:22<43:53,  1.51it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2# ÌïôÏäµÎêú Î™®Îç∏ Ï∞æÍ∏∞\n",
        "import glob as gb\n",
        "\n",
        "weight_files = gb.glob(f\"{PROJECT_DIR}/**/best.pt\", recursive=True)\n",
        "if weight_files:\n",
        "    BEST_WEIGHTS = weight_files[0]\n",
        "    print(f\"‚úÖ Î™®Îç∏ Î∞úÍ≤¨: {BEST_WEIGHTS}\")\n",
        "else:\n",
        "    BEST_WEIGHTS = os.path.join(PROJECT_DIR, \"pneumonia_baseline\", \"weights\", \"best.pt\")\n",
        "    print(f\"‚ö†Ô∏è Í∏∞Î≥∏ Í≤ΩÎ°ú ÏÇ¨Ïö©: {BEST_WEIGHTS}\")"
      ],
      "metadata": {
        "id": "3DsrfoqriTPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "results_path = os.path.join(PROJECT_DIR, \"pneumonia_baseline\")\n",
        "results_csv = os.path.join(results_path, \"results.csv\")\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    df = pd.read_csv(results_csv)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    last_epoch = df.iloc[-1]\n",
        "\n",
        "    precision_cols = [col for col in df.columns if 'precision' in col.lower()]\n",
        "    recall_cols = [col for col in df.columns if 'recall' in col.lower()]\n",
        "\n",
        "    if precision_cols and recall_cols:\n",
        "        precision = last_epoch[precision_cols[0]]\n",
        "        recall = last_epoch[recall_cols[0]]\n",
        "\n",
        "        # Validation GT Î∞ïÏä§ Ïàò\n",
        "        valid_labels_dir = os.path.join(DATASET[\"root\"], \"valid\", \"labels\")\n",
        "        valid_labels = list(Path(valid_labels_dir).glob(\"*.txt\"))\n",
        "        total_gt_boxes = sum(len(open(f).readlines()) for f in valid_labels)\n",
        "\n",
        "        # TP, FP, FN Í≥ÑÏÇ∞\n",
        "        TP = int(recall * total_gt_boxes)\n",
        "        FN = total_gt_boxes - TP\n",
        "        FP = int((TP / precision) - TP) if precision > 0 else 0\n",
        "        TN = 0\n",
        "\n",
        "        # Confusion Matrix ÏãúÍ∞ÅÌôî\n",
        "        cm = np.array([[TP, FN],\n",
        "                       [FP, TN]])\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Pneumonia', 'Background'],\n",
        "                    yticklabels=['Pneumonia', 'Background'],\n",
        "                    cbar_kws={'label':'Count'})\n",
        "        plt.ylabel('Predicted')\n",
        "        plt.xlabel('Actual')\n",
        "        plt.title('Confusion Matrix (Counts)')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "HGFnihbwiUyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}