{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm","mount_file_id":"1CmpJ8bysyL4K1AGzFvqIez9lqMrlamNy","authorship_tag":"ABX9TyN9uWEecR9N6JSpZ6pkhdYB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#í•„ìˆ˜ ì„¤ì¹˜+ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","!pip -q install ultralytics==8.* opencv-python\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwWRjx-MFHd1","executionInfo":{"status":"ok","timestamp":1768457829753,"user_tz":-540,"elapsed":4995,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"1f06f1ba-03ba-4200-c8da-79b21519ff4f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#ë“œë¼ì´ë¸Œ zip ë³µì‚¬í›„ ì••ì¶• í•´ì œ\n","import os, zipfile, shutil\n","\n","# (ì˜ˆì‹œ) ë„¤ ë“œë¼ì´ë¸Œ ì•ˆì— ìˆëŠ” zip ê²½ë¡œë¡œ ìˆ˜ì •\n","ZIP_IN_DRIVE = \"/content/drive/MyDrive/rsna-pneumonia-detector.v1i.yolov8.zip\"\n","\n","WORKDIR = \"/content/dataset\"\n","os.makedirs(WORKDIR, exist_ok=True)\n","\n","zip_local = \"/content/rsna.zip\"\n","shutil.copy(ZIP_IN_DRIVE, zip_local)\n","\n","with zipfile.ZipFile(zip_local, 'r') as z:\n","    z.extractall(WORKDIR)\n","\n","print(\"Extracted to:\", WORKDIR)\n","!ls -la /content/dataset | head -n 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezGg81WNFPRH","executionInfo":{"status":"ok","timestamp":1768457834756,"user_tz":-540,"elapsed":5006,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"c3362a16-2aca-4a28-b3cf-92c2c1070488"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted to: /content/dataset\n","total 32\n","drwxr-xr-x 5 root root 4096 Jan 15 04:40 .\n","drwxr-xr-x 1 root root 4096 Jan 15 06:14 ..\n","-rw-r--r-- 1 root root  301 Jan 15 06:17 data.yaml\n","-rw-r--r-- 1 root root  170 Jan 15 06:17 README.dataset.txt\n","-rw-r--r-- 1 root root 1141 Jan 15 06:17 README.roboflow.txt\n","drwxr-xr-x 4 root root 4096 Jan 15 04:40 test\n","drwxr-xr-x 4 root root 4096 Jan 15 04:41 train\n","drwxr-xr-x 4 root root 4096 Jan 15 04:41 valid\n"]}]},{"cell_type":"code","source":["#yaml ìœ„ì¹˜\n","import glob\n","\n","yamls = glob.glob(\"/content/dataset/**/*.yaml\", recursive=True)\n","yamls[:20], len(yamls)\n","\n","DATA_YAML = yamls[0]\n","print(\"Using:\", DATA_YAML)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExOZtKAdFijh","executionInfo":{"status":"ok","timestamp":1768457834824,"user_tz":-540,"elapsed":63,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"a7cf5cec-cffb-4db7-d628-2da4c6d688ad"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Using: /content/dataset/data.yaml\n"]}]},{"cell_type":"code","source":["#yaml\n","import yaml, pprint\n","\n","with open(DATA_YAML, \"r\") as f:\n","    cfg = yaml.safe_load(f)"],"metadata":{"id":"XkJmwcDDFvhC","executionInfo":{"status":"ok","timestamp":1768457834850,"user_tz":-540,"elapsed":24,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["#í í¬ìŠ¤íŒ…\n","import os, glob, shutil\n","import cv2\n","import numpy as np\n","\n","# --- í ë§ˆìŠ¤í‚¹ + ëŒ€ë¹„ê°œì„  í•¨ìˆ˜(ê°„ë‹¨ ë²„ì „) ---\n","def enhance_contrast_clahe(gray, clipLimit=2.0, tileGridSize=(8,8)):\n","    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","    return clahe.apply(gray)\n","\n","def lung_mask_simple(gray):\n","    g = cv2.GaussianBlur(gray, (5,5), 0)\n","    _, th = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","\n","    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n","    th = cv2.morphologyEx(th, cv2.MORPH_OPEN, k, iterations=1)\n","    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, k, iterations=2)\n","\n","    n, labels, stats, _ = cv2.connectedComponentsWithStats(th, connectivity=8)\n","    mask = np.zeros_like(th)\n","    if n > 1:\n","        areas = stats[1:, cv2.CC_STAT_AREA]\n","        idx = np.argsort(areas)[::-1][:3]  # í° ì»´í¬ë„ŒíŠ¸ 2~3ê°œ ìœ ì§€\n","        for kidx in idx:\n","            mask[labels == (kidx+1)] = 255\n","\n","    mask = cv2.GaussianBlur(mask, (11,11), 0)\n","    mask = (mask > 50).astype(np.uint8) * 255\n","    return mask\n","\n","def apply_lung_preproc(img_bgr):\n","    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","    mask = lung_mask_simple(gray)\n","    masked = cv2.bitwise_and(gray, gray, mask=mask)\n","    enhanced = enhance_contrast_clahe(masked, clipLimit=2.0, tileGridSize=(8,8))\n","    return enhanced  # grayscale\n","\n","# --- ì›ë³¸/ì „ì²˜ë¦¬ ë£¨íŠ¸ ---\n","SRC_ROOT = \"/content/dataset\"\n","DST_ROOT = \"/content/dataset_preproc\"\n","\n","# Roboflow ìŠ¤íƒ€ì¼(split/images, split/labels)ì´ë¼ê³  ê°€ì •\n","splits = [\"train\", \"valid\", \"test\"]\n","\n","# ìƒˆ í´ë” ì´ˆê¸°í™”\n","if os.path.exists(DST_ROOT):\n","    shutil.rmtree(DST_ROOT)\n","os.makedirs(DST_ROOT, exist_ok=True)\n","\n","for sp in splits:\n","    src_img = os.path.join(SRC_ROOT, sp, \"images\")\n","    src_lbl = os.path.join(SRC_ROOT, sp, \"labels\")\n","    if not os.path.isdir(src_img):\n","        continue\n","\n","    dst_img = os.path.join(DST_ROOT, sp, \"images\")\n","    dst_lbl = os.path.join(DST_ROOT, sp, \"labels\")\n","    os.makedirs(dst_img, exist_ok=True)\n","    os.makedirs(dst_lbl, exist_ok=True)\n","\n","    # labelsëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬ (bboxëŠ” ê·¸ëŒ€ë¡œ ìœ íš¨)\n","    if os.path.isdir(src_lbl):\n","        shutil.copytree(src_lbl, dst_lbl, dirs_exist_ok=True)\n","\n","    img_paths = sorted(glob.glob(src_img + \"/*\"))\n","    print(sp, \"images:\", len(img_paths))\n","\n","    for p in img_paths:\n","        im = cv2.imread(p)\n","        if im is None:\n","            continue\n","        out = apply_lung_preproc(im)\n","        cv2.imwrite(os.path.join(dst_img, os.path.basename(p)), out)\n","\n","print(\"Preprocessed dataset saved to:\", DST_ROOT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruL6UwYqRK4W","executionInfo":{"status":"ok","timestamp":1768462141109,"user_tz":-540,"elapsed":203735,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"9cefb1e9-c527-47e1-e45b-0b3f29ce9cec"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["train images: 11796\n","valid images: 1140\n","test images: 558\n","Preprocessed dataset saved to: /content/dataset_preproc\n"]}]},{"cell_type":"code","source":["#ì´ë¯¸ì§€ê°œì„ \n","import os, glob, shutil\n","import cv2\n","import numpy as np\n","\n","# (1) ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤\n","def enhance_contrast_clahe(gray, clipLimit=2.0, tileGridSize=(8,8)):\n","    \"\"\"ëª…ì•”/ëŒ€ë¹„ ê°œì„ (CLAHE): ì˜ë£Œì˜ìƒì—ì„œ ìì£¼ ì‚¬ìš©\"\"\"\n","    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","    return clahe.apply(gray)\n","\n","def gamma_correction(gray, gamma=1.2):\n","    \"\"\"ê°ë§ˆ ë³´ì •: 1.0ë³´ë‹¤ í¬ë©´ ì „ì²´ê°€ ì¡°ê¸ˆ ë°ì•„ì§€ëŠ” ê²½í–¥(ìƒí™©ì— ë”°ë¼ ì¡°ì ˆ)\"\"\"\n","    inv = 1.0 / gamma\n","    table = np.array([(i / 255.0) ** inv * 255 for i in range(256)]).astype(\"uint8\")\n","    return cv2.LUT(gray, table)\n","\n","def unsharp_mask(gray, sigma=1.0, strength=1.1):\n","    \"\"\"ì„ ëª…ë„ ê°œì„ (ì—£ì§€ ê°•í™”). ê³¼í•˜ë©´ ë…¸ì´ì¦ˆ ì¦ê°€\"\"\"\n","    blurred = cv2.GaussianBlur(gray, (0,0), sigmaX=sigma, sigmaY=sigma)\n","    sharp = cv2.addWeighted(gray, 1.0 + strength, blurred, -strength, 0)\n","    return np.clip(sharp, 0, 255).astype(np.uint8)\n","\n","def lung_mask_simple(gray):\n","    \"\"\"\n","    ê°„ë‹¨ í ROI ë§ˆìŠ¤í¬(í‰ë¶€ X-rayì— ë§ì¶˜ íœ´ë¦¬ìŠ¤í‹±)\n","    - ì™„ë²½í•œ ë¶„í• ì€ ì•„ë‹ˆì§€ë§Œ 'ë°°ê²½ ì–µì œ' ëª©ì ìœ¼ë¡  ì“¸ë§Œí•¨\n","    \"\"\"\n","    g = cv2.GaussianBlur(gray, (5,5), 0)\n","\n","    # Otsu + Invert (í‰ë¶€ì—ì„œ ë°°ê²½/ê¸°ê¸° ì˜ì—­ ì œê±°ìš©)\n","    _, th = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","\n","    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n","    th = cv2.morphologyEx(th, cv2.MORPH_OPEN, k, iterations=1)\n","    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, k, iterations=2)\n","\n","    n, labels, stats, _ = cv2.connectedComponentsWithStats(th, connectivity=8)\n","    mask = np.zeros_like(th)\n","\n","    if n > 1:\n","        areas = stats[1:, cv2.CC_STAT_AREA]\n","        idx = np.argsort(areas)[::-1][:3]  # í° ë©ì–´ë¦¬ 2~3ê°œ ìœ ì§€(ì¢Œ/ìš° í ëŒ€ì‘)\n","        for kidx in idx:\n","            mask[labels == (kidx+1)] = 255\n","\n","    # ê²½ê³„ ë¶€ë“œëŸ½ê²Œ\n","    mask = cv2.GaussianBlur(mask, (11,11), 0)\n","    mask = (mask > 50).astype(np.uint8) * 255\n","    return mask\n","\n","def preprocess_xray(img_bgr,\n","                    use_clahe=True,\n","                    use_gamma=False,\n","                    gamma=1.2,\n","                    use_unsharp=True):\n","    \"\"\"\n","    ìˆœì„œ:\n","    1) grayscale\n","    2) lung ROI ë§ˆìŠ¤í¬ ì ìš©(ë°°ê²½ ì–µì œ)\n","    3) CLAHEë¡œ ëŒ€ë¹„ ê°œì„ \n","    4) (ì„ íƒ) ê°ë§ˆ\n","    5) (ì„ íƒ) unsharp\n","    \"\"\"\n","    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","\n","    # (A) í ROI ë§ˆìŠ¤í‚¹\n","    mask = lung_mask_simple(gray)\n","    roi = cv2.bitwise_and(gray, gray, mask=mask)\n","\n","    # (B) ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ \n","    out = roi\n","    if use_clahe:\n","        out = enhance_contrast_clahe(out, clipLimit=2.0, tileGridSize=(8,8))\n","    if use_gamma:\n","        out = gamma_correction(out, gamma=gamma)\n","    if use_unsharp:\n","        out = unsharp_mask(out, sigma=1.0, strength=1.1)\n","\n","    return out  # grayscale (H,W)\n","\n","# (2) í´ë” ì „ì²´ ì „ì²˜ë¦¬: imagesë§Œ ìƒˆë¡œ ë§Œë“¤ê³  labelsëŠ” ë³µì‚¬\n","SRC_ROOT = \"/content/dataset\"\n","DST_ROOT = \"/content/dataset_preproc\"\n","\n","splits = [\"train\", \"valid\", \"test\"]  #ë°ì´í„° êµ¬ì¡°ê°€ ì´ í˜•íƒœë¼ë©´ ê·¸ëŒ€ë¡œ\n","\n","if os.path.exists(DST_ROOT):\n","    shutil.rmtree(DST_ROOT)\n","os.makedirs(DST_ROOT, exist_ok=True)\n","\n","for sp in splits:\n","    src_img_dir = os.path.join(SRC_ROOT, sp, \"images\")\n","    src_lbl_dir = os.path.join(SRC_ROOT, sp, \"labels\")\n","\n","    if not os.path.isdir(src_img_dir):\n","        continue\n","\n","    dst_img_dir = os.path.join(DST_ROOT, sp, \"images\")\n","    dst_lbl_dir = os.path.join(DST_ROOT, sp, \"labels\")\n","    os.makedirs(dst_img_dir, exist_ok=True)\n","    os.makedirs(dst_lbl_dir, exist_ok=True)\n","\n","    # labels ë³µì‚¬ (bboxëŠ” ê·¸ëŒ€ë¡œ ìœ íš¨)\n","    if os.path.isdir(src_lbl_dir):\n","        shutil.copytree(src_lbl_dir, dst_lbl_dir, dirs_exist_ok=True)\n","\n","    img_paths = sorted(glob.glob(src_img_dir + \"/*\"))\n","    print(f\"[{sp}] images:\", len(img_paths))\n","\n","    for p in img_paths:\n","        img = cv2.imread(p)\n","        if img is None:\n","            continue\n","        out = preprocess_xray(img, use_clahe=True, use_gamma=False, use_unsharp=True)\n","        cv2.imwrite(os.path.join(dst_img_dir, os.path.basename(p)), out)\n","\n","print(\" Preprocessed dataset saved to:\", DST_ROOT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKchas1bfatL","executionInfo":{"status":"ok","timestamp":1768464783882,"user_tz":-540,"elapsed":221082,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"7220380e-31f9-47be-95db-3f1c20409568"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[train] images: 11796\n","[valid] images: 1140\n","[test] images: 558\n"," Preprocessed dataset saved to: /content/dataset_preproc\n"]}]},{"cell_type":"code","source":["#í•™ìŠµ\n","from ultralytics import YOLO\n","\n","model = YOLO(\"yolov8s.pt\")\n","\n","results = model.train(\n","    data=DATA_YAML,\n","    epochs=15,\n","    imgsz=640,\n","    batch=16,\n","    device=0,\n","    workers=2,\n","    project=\"/content/runs\",\n","    name=\"rsna_yolov8s_153\",\n","    patience=0\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVRH2J0xGKlX","executionInfo":{"status":"ok","timestamp":1768467073533,"user_tz":-540,"elapsed":2278747,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"c18c16cf-80d1-4fcc-bc4c-eb2d627cebba"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.4.2 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=rsna_yolov8s_153, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/rsna_yolov8s_153, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n","Model summary: 130 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1131.0Â±404.8 MB/s, size: 35.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels.cache... 11796 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11796/11796 3.5Git/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 398.2Â±114.2 MB/s, size: 31.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels.cache... 1140 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1140/1140 73.6Mit/s 0.0s\n","Plotting labels to /content/runs/rsna_yolov8s_153/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/runs/rsna_yolov8s_153\u001b[0m\n","Starting training for 15 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/15      4.24G      2.115       2.83      2.087         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 3.9it/s 3:08\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.4it/s 6.6s\n","                   all       1140       1793      0.471      0.484      0.433      0.154\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/15      4.68G      1.822      1.871      1.773         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 4.7it/s 2:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.3it/s 6.7s\n","                   all       1140       1793      0.508      0.534      0.497      0.189\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/15      4.68G      1.776      1.773      1.721         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.1it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793        0.5      0.551      0.503      0.193\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/15      4.68G      1.765       1.73      1.713          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793      0.527      0.527      0.525      0.201\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/15      4.68G      1.726      1.674      1.677         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793      0.529      0.498      0.495       0.18\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/15      4.68G      1.775      1.525      1.784          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.5it/s 6.6s\n","                   all       1140       1793      0.523      0.595      0.533      0.197\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/15      4.68G      1.706      1.415      1.723          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.4s\n","                   all       1140       1793      0.498      0.574      0.487      0.177\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/15      4.68G       1.64        1.3      1.678          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793      0.572      0.576      0.538      0.196\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/15      4.68G      1.559      1.181      1.605          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793      0.533      0.551      0.501      0.184\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/15      4.68G      1.482      1.062      1.536          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.4s\n","                   all       1140       1793      0.514      0.594      0.497      0.182\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/15      4.68G      1.408     0.9607      1.471          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.3s\n","                   all       1140       1793      0.508      0.596      0.489      0.178\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/15      4.68G      1.333      0.871      1.416          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.4s\n","                   all       1140       1793      0.527      0.579      0.505      0.178\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/15      4.68G      1.267     0.7864      1.361          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.6it/s 6.4s\n","                   all       1140       1793      0.495      0.598      0.482      0.173\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/15      4.68G      1.208     0.7219      1.323          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.4s\n","                   all       1140       1793       0.52        0.6      0.503      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/15      4.68G       1.16     0.6764      1.283          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 738/738 5.3it/s 2:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.7it/s 6.3s\n","                   all       1140       1793      0.514      0.588       0.49      0.171\n","\n","15 epochs completed in 0.629 hours.\n","Optimizer stripped from /content/runs/rsna_yolov8s_153/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/runs/rsna_yolov8s_153/weights/best.pt, 22.5MB\n","\n","Validating /content/runs/rsna_yolov8s_153/weights/best.pt...\n","Ultralytics 8.4.2 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 73 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 36/36 5.0it/s 7.1s\n","                   all       1140       1793      0.526      0.528      0.525      0.201\n","Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n","Results saved to \u001b[1m/content/runs/rsna_yolov8s_153\u001b[0m\n"]}]},{"cell_type":"code","source":["#ì €ì¥ ê²°ê³¼\n","import glob\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","run_dir = \"/content/runs/detect/rsna_yolov8s_153\"\n","imgs = [\n","    \"results.png\",\n","    \"confusion_matrix.png\",\n","    \"PR_curve.png\",\n","    \"F1_curve.png\",\n","    \"P_curve.png\",\n","    \"R_curve.png\"\n","]\n","\n","for fn in imgs:\n","    p = f\"{run_dir}/{fn}\"\n","    if os.path.exists(p):\n","        img = Image.open(p)\n","        plt.figure(figsize=(12,6))\n","        plt.imshow(img)\n","        plt.axis(\"off\")\n","        plt.title(fn)\n","        plt.show()\n","    else:\n","        print(\"Not found:\", p)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlayV1l7Gc6L","executionInfo":{"status":"ok","timestamp":1768467105647,"user_tz":-540,"elapsed":67,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"0240a993-e964-4467-ec98-0db8a9d7ae74"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Not found: /content/runs/detect/rsna_yolov8s_153/results.png\n","Not found: /content/runs/detect/rsna_yolov8s_153/confusion_matrix.png\n","Not found: /content/runs/detect/rsna_yolov8s_153/PR_curve.png\n","Not found: /content/runs/detect/rsna_yolov8s_153/F1_curve.png\n","Not found: /content/runs/detect/rsna_yolov8s_153/P_curve.png\n","Not found: /content/runs/detect/rsna_yolov8s_153/R_curve.png\n"]}]},{"cell_type":"code","source":["#ì‹œê°í™”\n","import os, glob, cv2\n","import numpy as np\n","from ultralytics import YOLO\n","\n","RUN_DIR  = \"/content/runs/rsna_yolov8s_153\"\n","BEST_PT  = f\"{RUN_DIR}/weights/best.pt\"\n","OUT_DIR  = \"/content/gt_pred_overlay_s153\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# ---- (1) ì´ë¯¸ì§€/ë¼ë²¨ í´ë” ìë™ ì°¾ê¸° ----\n","def pick_dir(cands):\n","    cands = [p for p in cands if os.path.isdir(p)]\n","    scored = []\n","    for p in cands:\n","        n = len(glob.glob(os.path.join(p, \"*\")))\n","        scored.append((n, p))\n","    scored.sort(reverse=True)\n","    return scored[0][1] if scored and scored[0][0] > 0 else None, scored\n","\n","img_cands = (\n","    glob.glob(\"/content/dataset/**/valid/images\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/val/images\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/images/val\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/test/images\", recursive=True)\n",")\n","\n","lbl_cands = (\n","    glob.glob(\"/content/dataset/**/valid/labels\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/val/labels\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/labels/val\", recursive=True) +\n","    glob.glob(\"/content/dataset/**/test/labels\", recursive=True)\n",")\n","\n","IMG_DIR, img_scored = pick_dir(img_cands)\n","LBL_DIR, lbl_scored = pick_dir(lbl_cands)\n","\n","print(\"IMG candidates (top):\", img_scored[:5])\n","print(\"LBL candidates (top):\", lbl_scored[:5])\n","print(\"Using IMG_DIR:\", IMG_DIR)\n","print(\"Using LBL_DIR:\", LBL_DIR)\n","\n","assert IMG_DIR is not None, \"ì´ë¯¸ì§€ í´ë”ë¥¼ ëª» ì°¾ì•˜ì–´. dataset êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•¨.\"\n","assert LBL_DIR is not None, \"ë¼ë²¨ í´ë”ë¥¼ ëª» ì°¾ì•˜ì–´. dataset êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•¨.\"\n","\n","# ---- (2) ìœ í‹¸ ----\n","def yolo_to_xyxy(xc, yc, w, h, img_w, img_h):\n","    x1 = (xc - w/2) * img_w\n","    y1 = (yc - h/2) * img_h\n","    x2 = (xc + w/2) * img_w\n","    y2 = (yc + h/2) * img_h\n","    return np.array([x1, y1, x2, y2], dtype=np.float32)\n","\n","def box_iou_xyxy(a, b):\n","    x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n","    x2 = min(a[2], b[2]); y2 = min(a[3], b[3])\n","    inter = max(0, x2-x1) * max(0, y2-y1)\n","    area_a = max(0, a[2]-a[0]) * max(0, a[3]-a[1])\n","    area_b = max(0, b[2]-b[0]) * max(0, b[3]-b[1])\n","    union = area_a + area_b - inter + 1e-9\n","    return inter / union\n","\n","def read_yolo_labels(txt_path):\n","    if not os.path.exists(txt_path):\n","        return []\n","    items = []\n","    with open(txt_path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                continue\n","            p = line.split()\n","            cls = int(float(p[0]))\n","            xc, yc, bw, bh = map(float, p[1:5])\n","            items.append((cls, xc, yc, bw, bh))\n","    return items\n","\n","def draw_box(img, box_xyxy, color_bgr, text=None, thickness=2):\n","    x1,y1,x2,y2 = box_xyxy.astype(int)\n","    x1 = max(0, x1); y1 = max(0, y1)\n","    x2 = min(img.shape[1]-1, x2); y2 = min(img.shape[0]-1, y2)\n","    cv2.rectangle(img, (x1,y1), (x2,y2), color_bgr, thickness)\n","    if text:\n","        (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n","        cv2.rectangle(img, (x1, max(0, y1-th-6)), (x1+tw+6, y1), color_bgr, -1)\n","        cv2.putText(img, text, (x1+3, y1-4),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n","\n","# ---- (3) ì‹¤í–‰ ----\n","model = YOLO(BEST_PT)\n","\n","img_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*\")))\n","print(\"num images:\", len(img_paths))\n","\n","# ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ë¶€ë§Œ(ì›í•˜ë©´ ìˆ«ì ë°”ê¿”)\n","MAX_N = min(50, len(img_paths))\n","\n","for img_path in img_paths[:MAX_N]:\n","    img = cv2.imread(img_path)\n","    if img is None:\n","        continue\n","    H, W = img.shape[:2]\n","\n","    base = os.path.splitext(os.path.basename(img_path))[0]\n","    gt_txt = os.path.join(LBL_DIR, base + \".txt\")\n","\n","    # GT boxes (íŒŒë‘)\n","    gt_list = read_yolo_labels(gt_txt)\n","    gt_boxes = [(cls, yolo_to_xyxy(xc,yc,bw,bh,W,H)) for cls,xc,yc,bw,bh in gt_list]\n","\n","    # Pred boxes (ë¹¨ê°•)\n","    r = model.predict(source=img_path, conf=0.25, verbose=False)[0]\n","    pred_boxes = []\n","    if r.boxes is not None and len(r.boxes) > 0:\n","        xyxy = r.boxes.xyxy.cpu().numpy().astype(np.float32)\n","        conf = r.boxes.conf.cpu().numpy()\n","        cls  = r.boxes.cls.cpu().numpy().astype(int)\n","        for c, b, s in zip(cls, xyxy, conf):\n","            pred_boxes.append((c, b, float(s)))\n","\n","    # Pred ë¨¼ì € ê·¸ë¦¼(ë¹¨ê°•)\n","    for c, b, s in pred_boxes:\n","        draw_box(img, b, (0,0,255), text=f\"Pred c{c} {s:.2f}\", thickness=2)\n","\n","    # GT ê·¸ë¦¼ + IoU í‘œì‹œ(íŒŒë‘)\n","    for gt_c, gt_b in gt_boxes:\n","        best_iou = 0.0\n","        best = None\n","        for pc, pb, ps in pred_boxes:\n","            # í´ë˜ìŠ¤ê¹Œì§€ ì¼ì¹˜ ë§¤ì¹­í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ\n","            # if pc != gt_c:\n","            #     continue\n","            iou = box_iou_xyxy(gt_b, pb)\n","            if iou > best_iou:\n","                best_iou = iou\n","                best = (pc, pb, ps)\n","\n","        draw_box(img, gt_b, (255,0,0), text=f\"GT c{gt_c} IoU={best_iou:.3f}\", thickness=2)\n","\n","        # ë§¤ì¹­ëœ predëŠ” ì¡°ê¸ˆ ë‘ê»ê²Œ ê°•ì¡°\n","        if best is not None and best_iou > 0:\n","            pc, pb, ps = best\n","            draw_box(img, pb, (0,0,255), text=f\"Matched IoU={best_iou:.3f}\", thickness=3)\n","\n","    cv2.imwrite(os.path.join(OUT_DIR, base + \"_overlay.jpg\"), img)\n","\n","print(\"Saved overlays to:\", OUT_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSn4PTmGQn7g","executionInfo":{"status":"ok","timestamp":1768467109052,"user_tz":-540,"elapsed":1218,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"94ecb7ca-9295-4d60-ee4a-b3a46e62c412"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["IMG candidates (top): [(1140, '/content/dataset/valid/images'), (558, '/content/dataset/test/images')]\n","LBL candidates (top): [(1140, '/content/dataset/valid/labels'), (558, '/content/dataset/test/labels')]\n","Using IMG_DIR: /content/dataset/valid/images\n","Using LBL_DIR: /content/dataset/valid/labels\n","num images: 1140\n","Saved overlays to: /content/gt_pred_overlay_s153\n"]}]},{"cell_type":"code","source":["#í•™ìŠµ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸\n","!find /content -maxdepth 6 -type f -name \"results.csv\" -o -name \"results.png\" | head -n 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDpskFOlRyFt","executionInfo":{"status":"ok","timestamp":1768464456984,"user_tz":-540,"elapsed":284,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"e5d31757-1404-47aa-c342-d6c950206d76"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/runs/rsna_yolov8s_15/results.csv\n","/content/runs/rsna_yolov8s_15/results.png\n","/content/runs/rsna_yolov8n_15/results.csv\n","/content/runs/rsna_yolov8n_15/results.png\n","/content/runs/rsna_yolov8s_1522/results.csv\n","/content/runs/rsna_yolov8s_1522/results.png\n"]}]},{"cell_type":"code","source":["#ì‹¤í—˜ ê²°ê³¼ë„ì¶œ\n","import os, glob\n","import pandas as pd\n","import numpy as np\n","from ultralytics import YOLO\n","\n","RUNS = {\n","    \"YOLOv8s\": \"/content/runs/rsna_yolov8s_153\",  #ê²½ë¡œ\n","}\n","\n","#(val í´ë”ëŠ” ë„ˆ ìº¡ì²˜ëŒ€ë¡œ ì´ë¯¸ OK)\n","IMG_DIR = \"/content/dataset/valid/images\"\n","LBL_DIR = \"/content/dataset/valid/labels\"\n","\n","def pick_col(df, keys):\n","    for k in keys:\n","        if k in df.columns:\n","            return k\n","    return None\n","\n","def load_metrics_from_results_csv(run_dir):\n","    csv_path = os.path.join(run_dir, \"results.csv\")\n","    if not os.path.exists(csv_path):\n","        return None\n","    df = pd.read_csv(csv_path)\n","    last = df.iloc[-1]\n","    c_map50   = pick_col(df, [\"metrics/mAP50(B)\", \"metrics/mAP50\", \"map50\"])\n","    c_map     = pick_col(df, [\"metrics/mAP50-95(B)\", \"metrics/mAP50-95\", \"map\"])\n","    c_prec    = pick_col(df, [\"metrics/precision(B)\", \"metrics/precision\", \"precision\"])\n","    c_recall  = pick_col(df, [\"metrics/recall(B)\", \"metrics/recall\", \"recall\"])\n","    return {\n","        \"mAP50\": float(last[c_map50]) if c_map50 else np.nan,\n","        \"mAP50-95\": float(last[c_map]) if c_map else np.nan,\n","        \"Precision\": float(last[c_prec]) if c_prec else np.nan,\n","        \"Recall\": float(last[c_recall]) if c_recall else np.nan,\n","    }\n","\n","def yolo_txt_to_xyxy(txt_path, W, H):\n","    import numpy as np\n","    boxes = []\n","    if not os.path.exists(txt_path):\n","        return boxes\n","    with open(txt_path, \"r\") as f:\n","        for line in f:\n","            p = line.strip().split()\n","            if len(p) < 5:\n","                continue\n","            cls = int(float(p[0]))\n","            xc, yc, bw, bh = map(float, p[1:5])\n","            x1 = (xc - bw/2)*W; y1 = (yc - bh/2)*H\n","            x2 = (xc + bw/2)*W; y2 = (yc + bh/2)*H\n","            boxes.append((cls, np.array([x1,y1,x2,y2], dtype=np.float32)))\n","    return boxes\n","\n","def iou(a, b):\n","    x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n","    x2 = min(a[2], b[2]); y2 = min(a[3], b[3])\n","    inter = max(0, x2-x1) * max(0, y2-y1)\n","    area_a = max(0, a[2]-a[0]) * max(0, a[3]-a[1])\n","    area_b = max(0, b[2]-b[0]) * max(0, b[3]-b[1])\n","    return inter / (area_a + area_b - inter + 1e-9)\n","\n","def compute_fp_fn(model, img_dir, lbl_dir, conf=0.25, iou_thr=0.5, match_class=False, max_images=None):\n","    import cv2\n","    img_paths = sorted(glob.glob(os.path.join(img_dir, \"*\")))\n","    if max_images:\n","        img_paths = img_paths[:max_images]\n","    FP = 0; FN = 0\n","\n","    for img_path in img_paths:\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            continue\n","        H, W = img.shape[:2]\n","        base = os.path.splitext(os.path.basename(img_path))[0]\n","        gt_path = os.path.join(lbl_dir, base + \".txt\")\n","\n","        gt = yolo_txt_to_xyxy(gt_path, W, H)\n","        gt_used = [False]*len(gt)\n","\n","        r = model.predict(img_path, conf=conf, verbose=False)[0]\n","        preds = []\n","        if r.boxes is not None and len(r.boxes) > 0:\n","            xyxy = r.boxes.xyxy.cpu().numpy().astype(np.float32)\n","            cls  = r.boxes.cls.cpu().numpy().astype(int)\n","            for c, b in zip(cls, xyxy):\n","                preds.append((c, b))\n","        pred_used = [False]*len(preds)\n","\n","        for pi, (pc, pb) in enumerate(preds):\n","            best_i = -1; best_v = 0.0\n","            for gi, (gc, gb) in enumerate(gt):\n","                if gt_used[gi]:\n","                    continue\n","                if match_class and pc != gc:\n","                    continue\n","                v = iou(pb, gb)\n","                if v > best_v:\n","                    best_v = v; best_i = gi\n","            if best_i >= 0 and best_v >= iou_thr:\n","                pred_used[pi] = True\n","                gt_used[best_i] = True\n","\n","        FP += sum(1 for u in pred_used if not u)\n","        FN += sum(1 for u in gt_used if not u)\n","\n","    return FP, FN\n","\n","rows = []\n","for model_name, run_dir in RUNS.items():\n","    best_pt = os.path.join(run_dir, \"weights\", \"best.pt\")\n","    print(model_name, \"best.pt:\", best_pt, \"exists?\", os.path.exists(best_pt))\n","\n","    if not os.path.exists(best_pt):\n","        continue\n","\n","    m = load_metrics_from_results_csv(run_dir) or {\"mAP50\":np.nan,\"mAP50-95\":np.nan,\"Precision\":np.nan,\"Recall\":np.nan}\n","    model = YOLO(best_pt)\n","    FP, FN = compute_fp_fn(model, IMG_DIR, LBL_DIR, conf=0.25, iou_thr=0.5, match_class=False)\n","\n","    rows.append({\n","        \"ëª¨ë¸ ìŠ¤ì¼€ì¼\": model_name,\n","        \"mAP50\": m[\"mAP50\"],\n","        \"mAP50-95\": m[\"mAP50-95\"],\n","        \"Precision\": m[\"Precision\"],\n","        \"Recall\": m[\"Recall\"],\n","        \"FP (ì˜¤íƒ)\": FP,\n","        \"FN (ë¯¸íƒ)\": FN,\n","        \"ì´ ì—ëŸ¬ ìˆ˜\": FP + FN\n","    })\n","\n","df = pd.DataFrame(rows)\n","\n","print(\"\\n=== rows ê°œìˆ˜ ===\", len(rows))\n","print(df)              #ë¬´ì¡°ê±´ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥ë¼ì„œ â€œë¹ˆ í‘œì¸ì§€â€ ë°”ë¡œ í™•ì¸ ê°€ëŠ¥\n","df.style               #í‘œ ì˜ˆì˜ê²Œ ë Œë”ë§"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"C7BtWl7iU5MW","executionInfo":{"status":"ok","timestamp":1768467129370,"user_tz":-540,"elapsed":14529,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"bd97f46d-d3fc-49bf-9993-a20e80c74098"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv8s best.pt: /content/runs/rsna_yolov8s_153/weights/best.pt exists? True\n","\n","=== rows ê°œìˆ˜ === 1\n","    ëª¨ë¸ ìŠ¤ì¼€ì¼    mAP50  mAP50-95  Precision   Recall  FP (ì˜¤íƒ)  FN (ë¯¸íƒ)  ì´ ì—ëŸ¬ ìˆ˜\n","0  YOLOv8s  0.48973   0.17124    0.51445  0.58784      407     1069    1476\n"]},{"output_type":"execute_result","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x79c554386f30>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_d2cf0\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_d2cf0_level0_col0\" class=\"col_heading level0 col0\" >ëª¨ë¸ ìŠ¤ì¼€ì¼</th>\n","      <th id=\"T_d2cf0_level0_col1\" class=\"col_heading level0 col1\" >mAP50</th>\n","      <th id=\"T_d2cf0_level0_col2\" class=\"col_heading level0 col2\" >mAP50-95</th>\n","      <th id=\"T_d2cf0_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n","      <th id=\"T_d2cf0_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n","      <th id=\"T_d2cf0_level0_col5\" class=\"col_heading level0 col5\" >FP (ì˜¤íƒ)</th>\n","      <th id=\"T_d2cf0_level0_col6\" class=\"col_heading level0 col6\" >FN (ë¯¸íƒ)</th>\n","      <th id=\"T_d2cf0_level0_col7\" class=\"col_heading level0 col7\" >ì´ ì—ëŸ¬ ìˆ˜</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_d2cf0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_d2cf0_row0_col0\" class=\"data row0 col0\" >YOLOv8s</td>\n","      <td id=\"T_d2cf0_row0_col1\" class=\"data row0 col1\" >0.489730</td>\n","      <td id=\"T_d2cf0_row0_col2\" class=\"data row0 col2\" >0.171240</td>\n","      <td id=\"T_d2cf0_row0_col3\" class=\"data row0 col3\" >0.514450</td>\n","      <td id=\"T_d2cf0_row0_col4\" class=\"data row0 col4\" >0.587840</td>\n","      <td id=\"T_d2cf0_row0_col5\" class=\"data row0 col5\" >407</td>\n","      <td id=\"T_d2cf0_row0_col6\" class=\"data row0 col6\" >1069</td>\n","      <td id=\"T_d2cf0_row0_col7\" class=\"data row0 col7\" >1476</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["#íŒŒì¼ í¬ê¸°/ìˆ˜ì • ì‹œê°„ í™•ì¸\n","!ls -lh /content/runs/rsna_yolov8s_153/weights/best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7YDEkoijPbI","executionInfo":{"status":"ok","timestamp":1768467131806,"user_tz":-540,"elapsed":148,"user":{"displayName":"rhksgks dbs","userId":"08377218682296503876"}},"outputId":"316163c7-7579-4ed8-b2ca-eeed6ca3c15e"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-r--r-- 1 root root 22M Jan 15 08:51 /content/runs/rsna_yolov8s_153/weights/best.pt\n"]}]}]}